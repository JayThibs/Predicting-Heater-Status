{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Heater Status Notebook\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Given energy consumption time series data from t1, ..., tn, predict whether the water heater is ON (1) or OFF (0) at tn for multiple locations.\n",
    "\n",
    "### General observations of the data set\n",
    "\n",
    "• The data set has measurements based on 5 locations.\n",
    "\n",
    "• The time series does not exceed 7 days in duration.\n",
    "\n",
    "### Hypothesis on how to best solve the problem\n",
    "\n",
    "This is a binary classification problem with a time series as a predictor. Since we are working with a time series, the input features are not independent. We will have to seperate the train/validation/test sets in their own time periods. The training set will use the first half of the data set of each location, the validation set will use the next 1/4 and test set will use the final 1/4.\n",
    "\n",
    "Let's have a look at the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mains</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location01</td>\n",
       "      <td>2016-01-12 3:59:00</td>\n",
       "      <td>1536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location01</td>\n",
       "      <td>2016-01-12 4:00:00</td>\n",
       "      <td>2513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location01</td>\n",
       "      <td>2016-01-12 4:01:00</td>\n",
       "      <td>2582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location01</td>\n",
       "      <td>2016-01-12 4:02:00</td>\n",
       "      <td>2986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>location01</td>\n",
       "      <td>2016-01-12 4:03:00</td>\n",
       "      <td>1035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationId           timestamp  mains  status\n",
       "0  location01  2016-01-12 3:59:00   1536       0\n",
       "1  location01  2016-01-12 4:00:00   2513       0\n",
       "2  location01  2016-01-12 4:01:00   2582       0\n",
       "3  location01  2016-01-12 4:02:00   2986       0\n",
       "4  location01  2016-01-12 4:03:00   1035       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data Scientist Question - Training Data Set.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I will be comparing the following classification algorithms: Logistic Regression, Decision Tree, Random Forest, KNN, Linear Discriminant Analysis, Naive Bayes (Gaussian NB) and SVC. I could also build a model in tensorflow, but the data set is too limited and it would likely be a waste of time since it wouldn't perform much better than the other algorithms. Normally, I would test different hyperparameter for each algorithm (or at least the top 3), but due to time-constraints, I will simply choose the default parameters to compare the algorithms. After I have chosen an algorithm, I will optimize it.\n",
    "\n",
    "Since there are many more negative (OFF) cases than there are positive (ON) cases, the F1-Score will be a much better metric than the accuracy score. We will still calculate the accuracy score in order to get an idea of how many predictions we got right. However, when deciding on which model we choose, we will compare the F1-Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores in location order:  [94.51428571428572, 92.057142857142864, 80.450000000000003, 82.933333333333337, 92.25]\n",
      "F1-Scores in location order:  [0.64705882352941169, 0.29441624365482233, 0.48074369189907035, 0.56164383561643838, 0.70809792843691144]\n",
      "LR Accuracy score: 89.269841\n",
      "LR F1-Score: 0.555029\n",
      "confusion matrix\n",
      " [[6503  406]\n",
      " [ 439  527]]\n",
      "(row=expected, col=predicted) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacquesthibodeau/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores in location order:  [94.799999999999997, 92.114285714285714, 80.800000000000011, 83.200000000000003, 90.549999999999997]\n",
      "F1-Scores in location order:  [0.67148014440433224, 0.49264705882352944, 0.49869451697127931, 0.58823529411764708, 0.68656716417910446]\n",
      "LDA Accuracy score: 89.015873\n",
      "LDA F1-Score: 0.582327\n",
      "confusion matrix\n",
      " [[6407  502]\n",
      " [ 363  603]]\n",
      "(row=expected, col=predicted) \n",
      "\n",
      "Accuracy scores in location order:  [94.857142857142861, 75.771428571428572, 78.849999999999994, 73.333333333333329, 83.549999999999997]\n",
      "F1-Scores in location order:  [0.70000000000000007, 0.256140350877193, 0.52631578947368418, 0.41860465116279072, 0.48351648351648358]\n",
      "KNN Accuracy score: 82.653968\n",
      "KNN F1-Score: 0.468896\n",
      "confusion matrix\n",
      " [[5906 1003]\n",
      " [ 363  603]]\n",
      "(row=expected, col=predicted) \n",
      "\n",
      "Accuracy scores in location order:  [94.171428571428578, 83.142857142857139, 78.25, 71.733333333333334, 82.099999999999994]\n",
      "F1-Scores in location order:  [0.65306122448979598, 0.28915662650602408, 0.48520710059171596, 0.34567901234567905, 0.46084337349397592]\n",
      "CART Accuracy score: 83.542857\n",
      "CART F1-Score: 0.455462\n",
      "confusion matrix\n",
      " [[6037  872]\n",
      " [ 424  542]]\n",
      "(row=expected, col=predicted) \n",
      "\n",
      "Accuracy scores in location order:  [94.0, 79.942857142857136, 78.649999999999991, 72.0, 82.25]\n",
      "F1-Scores in location order:  [0.64882943143812699, 0.25477707006369427, 0.49227110582639722, 0.339622641509434, 0.46935724962630793]\n",
      "RF Accuracy score: 82.946032\n",
      "RF F1-Score: 0.449364\n",
      "confusion matrix\n",
      " [[5984  925]\n",
      " [ 418  548]]\n",
      "(row=expected, col=predicted) \n",
      "\n",
      "Accuracy scores in location order:  [94.799999999999997, 92.114285714285714, 80.800000000000011, 83.200000000000003, 91.100000000000009]\n",
      "F1-Scores in location order:  [0.67148014440433224, 0.49264705882352944, 0.49606299212598426, 0.58823529411764708, 0.69932432432432434]\n",
      "GNB Accuracy score: 89.155556\n",
      "GNB F1-Score: 0.584630\n",
      "confusion matrix\n",
      " [[6420  489]\n",
      " [ 365  601]]\n",
      "(row=expected, col=predicted) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEVCAYAAADwyx6sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111f8cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEVCAYAAAAb/KWvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm5kl6P8B7I6n61tYiZIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111ef2e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare algorithms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "# load dataset\n",
    "df = pd.read_csv('Data Scientist Question - Training Data Set.csv')\n",
    "\n",
    "# LabelEncoder helps us convert each location ID to an integer, \n",
    "# this makes it easier for classification\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['locationId'])\n",
    "df['locationId'] = le.transform(df['locationId'])\n",
    "\n",
    "# preparing arrays for loop\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "y_test_i = []\n",
    "X_validation = []\n",
    "y_validation = []\n",
    "y_validation_i = []\n",
    "i=0\n",
    "# this loop separates each location into their own data sets and\n",
    "# separates each of those data sets into train/validation/test sets\n",
    "    for location in df['locationId'].unique():\n",
    "    # training set contains the first 50% of data, the validation set will \n",
    "    # use the next 1/4 and test set will use the final 1/4.\n",
    "    train_size = int(len(df[df['locationId'] == location]['mains']) * 0.5)\n",
    "    validation_size = int(len(df[df['locationId'] == location]['mains']) * 0.75)\n",
    "    \n",
    "    # separating features and the target variable for a specific location ID\n",
    "    X = df[df['locationId'] == location]\n",
    "    X = X.ix[:,[0,2]].values\n",
    "    y = (df[df['locationId'] == location]['status']).values\n",
    "    \n",
    "    X_train.append({location: X[0:train_size]})\n",
    "    y_train.append({location: y[0:train_size]})\n",
    "    \n",
    "    X_validation.append(X[train_size:validation_size])\n",
    "    y_validation.append(y[train_size:validation_size])\n",
    "    y_validation_i.append({location: y[train_size:validation_size]})\n",
    "    \n",
    "    X_test.append(X[validation_size:])\n",
    "    y_test.append(y[validation_size:])\n",
    "    y_test_i.append({location: y[validation_size:]})\n",
    "    \n",
    "    i=i+1\n",
    "\n",
    "# for when we'll want to calculate the scores on the whole validation/test sets\n",
    "y_validation = [yi for sublist in y_validation for yi in sublist]\n",
    "y_test = [yi for sublist in y_test for yi in sublist]\n",
    "\n",
    "# prepare configuration for validation test harness\n",
    "seed = 3\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "all_scores_f1 = []\n",
    "all_scores_accuracy = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    # evaluate each model in turn\n",
    "    scores_f1 = []\n",
    "    scores_accuracy = []\n",
    "    predictions = []\n",
    "    i = 0\n",
    "    # let's fit each model to each location ID\n",
    "    for location_i in df['locationId'].unique():\n",
    "        # let's seperate our input features (X) from our target variables (y)\n",
    "        X_train_location_i = X_train[i][location_i]\n",
    "        y_train_location_i = y_train[i][location_i]\n",
    "        HeaterStatus = model\n",
    "        model_instance = HeaterStatus\n",
    "        model_instance.fit(X_train_location_i, y_train_location_i)\n",
    "\n",
    "        # let's predict the status of the heater at each timestep\n",
    "        prediction = []\n",
    "        for location, wattage in X_validation[i][:]:\n",
    "            prediction.append(model_instance.predict(np.array([[location, wattage]])))\n",
    "\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # we will now calculate the accuracy score and the F1-score.\n",
    "        # the F1-score is much more important because the accuracy score\n",
    "        # suffers from the Accuracy Paradox.\n",
    "        scores_accuracy.append(accuracy_score(y_validation_i[i][location_i], prediction)*100)\n",
    "        scores_f1.append(f1_score(y_validation_i[i][location_i], prediction))\n",
    "        i = i+1\n",
    "    \n",
    "    # let's collect all the scores and print them out to compare each algorithm\n",
    "    print(\"Accuracy scores in location order: \", scores_accuracy)\n",
    "    print(\"F1-Scores in location order: \", scores_f1)\n",
    "    all_scores_f1.append(scores_f1)\n",
    "    all_scores_accuracy.append(scores_accuracy)\n",
    "    names.append(name)\n",
    "    predictions = [yi for sublist in predictions for yi in sublist]\n",
    "    accuracy_msg = \"%s Accuracy score: %f\" % (name, accuracy_score(y_validation, predictions)*100)\n",
    "    print(accuracy_msg)\n",
    "    f1_msg = \"%s F1-Score: %f\" % (name, f1_score(y_validation, predictions))\n",
    "    print(f1_msg)\n",
    "    print('confusion matrix\\n', confusion_matrix(y_validation, predictions))\n",
    "    print('(row=expected, col=predicted) \\n')\n",
    "    \n",
    "# boxplot algorithm comparison (accuracy score)\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison (accuracy score)')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(all_scores_accuracy)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "    \n",
    "# boxplot algorithm comparison (F1-score)\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison (F1-score)')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(all_scores_f1)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "By looking at the results, Gaussian Naive Bayes performs the best on this data set. In the case of Gaussian Naive Bayes, it has no parameters to tune, so we will simply use the test set to get our final score after checking the validation score.\n",
    "\n",
    "---\n",
    "\n",
    "## Calculating the validation score of the selected algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores in location order:  [94.799999999999997, 92.114285714285714, 80.800000000000011, 83.200000000000003, 91.100000000000009]\n",
      "F1-Scores in location order:  [0.67148014440433224, 0.49264705882352944, 0.49606299212598426, 0.58823529411764708, 0.69932432432432434]\n",
      "Gaussian Naive Bayes Accuracy score on whole validation set: 89.155556\n",
      "Gaussian Naive Bayes F1-Score on whole validation set: 0.584630\n",
      "confusion matrix\n",
      " [[6420  489]\n",
      " [ 365  601]]\n",
      "(row=expected, col=predicted) \n",
      "\n",
      "Gaussian Naive Bayes Accuracy score mean (mean of all location): 88.402857\n",
      "Gaussian Naive Bayes F1-Score (mean of all location): 0.589550\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('Data Scientist Question - Training Data Set.csv')\n",
    "\n",
    "# LabelEncoder helps us convert each location ID to an integer, \n",
    "# this makes it easier for classification\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['locationId'])\n",
    "df['locationId'] = le.transform(df['locationId'])\n",
    "\n",
    "# preparing arrays for loop\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "y_test_i = []\n",
    "X_validation = []\n",
    "y_validation = []\n",
    "y_validation_i = []\n",
    "i=0\n",
    "# this loop separates each location into their own data sets and\n",
    "# separates each of those data sets into train/validation/test sets\n",
    "for location in df['locationId'].unique():\n",
    "    # training set contains the first 50% of data, the validation set will \n",
    "    # use the next 1/4 and test set will use the final 1/4.\n",
    "    train_size = int(len(df[df['locationId'] == location]['mains']) * 0.5)\n",
    "    validation_size = int(len(df[df['locationId'] == location]['mains']) * 0.75)\n",
    "    \n",
    "    # separating features and the target variable for a specific location ID\n",
    "    X = df[df['locationId'] == location]\n",
    "    X = X.ix[:,[0,2]].values\n",
    "    y = (df[df['locationId'] == location]['status']).values\n",
    "    \n",
    "    X_train.append({location: X[0:train_size]})\n",
    "    y_train.append({location: y[0:train_size]})\n",
    "    \n",
    "    X_validation.append(X[train_size:validation_size])\n",
    "    y_validation.append(y[train_size:validation_size])\n",
    "    y_validation_i.append({location: y[train_size:validation_size]})\n",
    "    \n",
    "    X_test.append(X[validation_size:])\n",
    "    y_test.append(y[validation_size:])\n",
    "    y_test_i.append({location: y[validation_size:]})\n",
    "    \n",
    "    i=i+1\n",
    "\n",
    "# for when we'll want to calculate the scores on the whole validation/test sets\n",
    "y_validation = [yi for sublist in y_validation for yi in sublist]\n",
    "y_test = [yi for sublist in y_test for yi in sublist]\n",
    "\n",
    "# prepare configuration for validation test harness\n",
    "seed = 3\n",
    "\n",
    "# prepare model\n",
    "name = 'Gaussian Naive Bayes'\n",
    "model = GaussianNB()\n",
    "        \n",
    "names = []\n",
    "scores_f1 = []\n",
    "scores_accuracy = []\n",
    "predictions = []\n",
    "i = 0\n",
    "# let's fit our model to each location ID\n",
    "for location_i in df['locationId'].unique():\n",
    "    X_train_location_i = X_train[i][location_i]\n",
    "    y_train_location_i = y_train[i][location_i]\n",
    "    HeaterStatus = model\n",
    "    model_instance = HeaterStatus\n",
    "    model_instance.fit(X_train_location_i, y_train_location_i)\n",
    "    \n",
    "    # let's predict the status of the heater at each timestep\n",
    "    prediction = []\n",
    "    for location, wattage in X_validation[i][:]:\n",
    "        prediction.append(model_instance.predict(np.array([[location, wattage]])))\n",
    "    \n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    # we will now calculate the accuracy score and the F1-score.\n",
    "    # the F1-score is much more important because the accuracy score\n",
    "    # suffers from the Accuracy Paradox.\n",
    "    scores_accuracy.append(accuracy_score(y_validation_i[i][location_i], prediction)*100)\n",
    "    scores_f1.append(f1_score(y_validation_i[i][location_i], prediction))\n",
    "    i = i+1\n",
    "    \n",
    "# let's collect all the scores and print them out\n",
    "print(\"Accuracy scores in location order: \", scores_accuracy)\n",
    "print(\"F1-Scores in location order: \", scores_f1)\n",
    "predictions = [yi for sublist in predictions for yi in sublist]\n",
    "accuracy_msg = \"%s Accuracy score on whole validation set: %f\" % (name, accuracy_score(y_validation, predictions)*100)\n",
    "print(accuracy_msg)\n",
    "f1_msg = \"%s F1-Score on whole validation set: %f\" % (name, f1_score(y_validation, predictions))\n",
    "print(f1_msg)\n",
    "print('confusion matrix\\n', confusion_matrix(y_validation, predictions))\n",
    "print('(row=expected, col=predicted) \\n')\n",
    "accuracy_msg = \"%s Accuracy score mean (mean of all location): %f\" % (name, np.mean(scores_accuracy))\n",
    "print(accuracy_msg)\n",
    "f1_msg = \"%s F1-Score (mean of all location): %f\" % (name, np.mean(scores_f1))\n",
    "print(f1_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Obviously, we get the same score since we can't parameter tune Gaussian NB. Now, let's check our final score on the test set.\n",
    "\n",
    "---\n",
    "\n",
    "## Checking the performance of the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores in location order:  [89.485714285714295, 90.457142857142856, 84.200000000000003, 88.799999999999997, 90.549999999999997]\n",
      "F1-Scores in location order:  [0.12380952380952381, 0.0, 0.67951318458417853, 0.39999999999999997, 0.6021052631578947]\n",
      "Gaussian Naive Bayes Accuracy score on whole test set: 88.596825\n",
      "Gaussian Naive Bayes F1-Score on whole test set: 0.529350\n",
      "confusion matrix\n",
      " [[6472  282]\n",
      " [ 616  505]]\n",
      "(row=expected, col=predicted) \n",
      "\n",
      "Gaussian Naive Bayes Accuracy score mean (mean of all location): 88.698571\n",
      "Gaussian Naive Bayes F1-Score (mean of all location): 0.361086\n"
     ]
    }
   ],
   "source": [
    "scores_f1 = []\n",
    "scores_accuracy = []\n",
    "predictions = []\n",
    "i=0\n",
    "# let's test our model's performance on each location ID\n",
    "for location_i in df['locationId'].unique():\n",
    "    X_test_location_i = X_test[i].reshape(-1,1)\n",
    "        \n",
    "    # let's predict the status of the heater at each timestep\n",
    "    prediction = []\n",
    "    for location, wattage in X_test[i][:]:\n",
    "        prediction.append(model_instance.predict(np.array([[location, wattage]])))\n",
    "            \n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    # we will now calculate the accuracy score and the F1-score.\n",
    "    # the F1-score is much more important because the accuracy score\n",
    "    # suffers from the Accuracy Paradox.\n",
    "    scores_accuracy.append(accuracy_score(y_test_i[i][location_i], prediction)*100)\n",
    "    scores_f1.append(f1_score(y_test_i[i][location_i], prediction))\n",
    "    i=i+1\n",
    "\n",
    "# let's collect all the scores and print them out to see the performance on the test set\n",
    "print(\"Accuracy scores in location order: \", scores_accuracy)\n",
    "print(\"F1-Scores in location order: \", scores_f1)\n",
    "predictions = [yi for sublist in predictions for yi in sublist]\n",
    "accuracy_msg = \"%s Accuracy score on whole test set: %f\" % (name, accuracy_score(y_test, predictions)*100)\n",
    "print(accuracy_msg)\n",
    "f1_msg = \"%s F1-Score on whole test set: %f\" % (name, f1_score(y_test, predictions))\n",
    "print(f1_msg)\n",
    "print('confusion matrix\\n', confusion_matrix(y_test, predictions))\n",
    "print('(row=expected, col=predicted) \\n')\n",
    "accuracy_msg = \"%s Accuracy score mean (mean of all location): %f\" % (name, np.mean(scores_accuracy))\n",
    "print(accuracy_msg)\n",
    "f1_msg = \"%s F1-Score (mean of all location): %f\" % (name, np.mean(scores_f1))\n",
    "print(f1_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The performance on the test is worse than the validation set. The model performed well on the final 3 locations, but it didn't perform so well on the first two. In the case of the second location, no true positive was predicted so we get a F1-Score of 0.\n",
    "\n",
    "We could improve this model by using feature selection and/or changing algorithm (particularly Linear Discriminant Analysis because of its performance on this data set) and tune its parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## Saving the model\n",
    "\n",
    "We can now save our model using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# we will now train our model on the entire data set\n",
    "X_final = df.ix[:,[0,2]].values\n",
    "y_final = df.ix[:,3].values\n",
    "\n",
    "HeaterStatus = model\n",
    "model_instance = HeaterStatus\n",
    "model_instance.fit(X_final, y_final)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'HeaterStatus.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# if we want to make new predictions, we can load the model from disk\n",
    "HeaterStatus = pickle.load(open(filename, 'rb'))\n",
    "negative_result = HeaterStatus.predict(np.array([[2, 5000]]))\n",
    "positive_result = HeaterStatus.predict(np.array([[3, 10000]]))\n",
    "print(negative_result)\n",
    "print(positive_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be very interesting to build a model with more features and a larger data set.\n",
    "\n",
    "Potential features:\n",
    "\n",
    "1. 6 or 8 hour window periods on each day of the week\n",
    "2. Temperature\n",
    "3. Humidity\n",
    "4. Weekdays vs weekends\n",
    "5. Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
